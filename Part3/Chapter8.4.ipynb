{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter8.4 TensorFlowで2層CNNを実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/\")\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    X = tf.placeholder(tf.float32, [None, 784], name='X')\n",
    "    y = tf.placeholder(tf.float32, [None, ], name='y')\n",
    "\n",
    "    X_image = tf.reshape(X, [-1, 28, 28, 1])\n",
    "\n",
    "    # 畳み込み層1層目\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=X_image,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"SAME\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # プーリング層1層目\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # 畳み込み層1層目\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"SAME\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # プーリング層2層目\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # 全結合層\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    dense = tf.layers.dense(\n",
    "        inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "    # ドロップアウト層\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense, rate=0.5, training=True)\n",
    "\n",
    "    # 出力層\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10, name='output')\n",
    "    predict = tf.argmax(logits, 1)\n",
    "\n",
    "    # 損失\n",
    "    with tf.name_scope('calc_loss'):\n",
    "        onehot_labels = tf.one_hot(indices=tf.cast(y, tf.int32), depth=10)\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=onehot_labels, logits=logits, name='xentropy')\n",
    "        loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "\n",
    "    # 損失の最適化\n",
    "    train_op = tf.train.AdamOptimizer(0.0001).minimize(loss)\n",
    "\n",
    "    # 正解率算出\n",
    "    with tf.name_scope('calc_accuracy'):\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.argmax(logits, 1), tf.argmax(onehot_labels, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        total_batch = int(mnist.train.num_examples // batch_size)\n",
    "        for epoch in range(20):\n",
    "            for step in range(total_batch):\n",
    "                batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "                _, loss_value = sess.run([train_op, loss],\n",
    "                                         feed_dict={X: batch_xs, y: batch_ys})\n",
    "            print('Step: %d, Loss: %f' % (step, loss_value))\n",
    "\n",
    "        # test\n",
    "        _a = sess.run(accuracy, feed_dict={\n",
    "                      X: mnist.test.images, y: mnist.test.labels})\n",
    "        print('Accuracy: %f' % _a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
